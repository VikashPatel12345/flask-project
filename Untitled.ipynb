{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyttsx3\n",
    "def text_to_speech(text, gender):\n",
    "    voice_dict = {'Male': 0, 'Female': 1}\n",
    "    code = voice_dict[gender]\n",
    "\n",
    "    engine = pyttsx3.init()\n",
    "    engine.setProperty('rate', 125)\n",
    "    engine.setProperty('volume', 0.8)\n",
    "    voices = engine.getProperty('voices')\n",
    "    engine.setProperty('voice', voices[code].id)\n",
    "\n",
    "    engine.say(text)\n",
    "    engine.runAndWait()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import speech_recognition as sr\n",
    "def takeCommand():\n",
    "    r = sr.Recognizer()\n",
    "    with sr.Microphone() as source:\n",
    "        print(\"Listening...\")\n",
    "        r.pause_threshold = 1\n",
    "        audio = r.listen(source)\n",
    "    try:\n",
    "        print(\"Recognizing...\")    \n",
    "        query = r.recognize_google(audio, language ='en-in')\n",
    "        print(f\"User said: {query}\\n\")\n",
    "    except Exception as e:\n",
    "        print(e)    \n",
    "        print(\"Unable to Recognize your voice.\")  \n",
    "        return \"None\"\n",
    "    return query\n",
    "#a=takeCommand()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "vocabulary loaded\n",
      "====================================================================================================\n",
      "MODEL LOADED\n",
      " * Serving Flask app \"__main__\" (lazy loading)\n",
      " * Environment: production\n",
      "   WARNING: This is a development server. Do not use it in a production deployment.\n",
      "   Use a production WSGI server instead.\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n",
      "127.0.0.1 - - [02/Feb/2021 10:24:40] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [02/Feb/2021 10:24:41] \"\u001b[37mGET /static/bootstrap.min.css HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [02/Feb/2021 10:24:41] \"\u001b[37mGET /static/styles.css HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [02/Feb/2021 10:24:42] \"\u001b[37mGET /static/logo.png HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [02/Feb/2021 10:24:43] \"\u001b[37mGET /static/1.jpg HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [02/Feb/2021 10:24:43] \"\u001b[37mGET /static/2.jpg HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [02/Feb/2021 10:24:44] \"\u001b[37mGET /static/favicon.ico HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "IMAGE SAVED\n",
      "Before Pred\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Predict Features\n",
      "==================================================\n",
      "GETING Captions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "127.0.0.1 - - [02/Feb/2021 10:25:45] \"\u001b[37mPOST /after HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [02/Feb/2021 10:25:47] \"\u001b[36mGET /static/bootstrap.min.css HTTP/1.1\u001b[0m\" 304 -\n",
      "127.0.0.1 - - [02/Feb/2021 10:25:47] \"\u001b[36mGET /static/styles.css HTTP/1.1\u001b[0m\" 304 -\n",
      "127.0.0.1 - - [02/Feb/2021 10:25:47] \"\u001b[37mGET /static/file.jpg HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [02/Feb/2021 10:25:48] \"\u001b[36mGET /static/1.jpg HTTP/1.1\u001b[0m\" 304 -\n",
      "127.0.0.1 - - [02/Feb/2021 10:25:48] \"\u001b[36mGET /static/2.jpg HTTP/1.1\u001b[0m\" 304 -\n",
      "127.0.0.1 - - [02/Feb/2021 10:30:09] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [02/Feb/2021 10:30:10] \"\u001b[37mGET /static/bootstrap.min.css HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [02/Feb/2021 10:30:12] \"\u001b[37mGET /static/logo.png HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [02/Feb/2021 10:30:13] \"\u001b[37mGET /static/favicon.ico HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [02/Feb/2021 10:30:21] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [02/Feb/2021 10:30:22] \"\u001b[37mGET /static/styles.css HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [02/Feb/2021 10:30:22] \"\u001b[36mGET /static/logo.png HTTP/1.1\u001b[0m\" 304 -\n",
      "127.0.0.1 - - [02/Feb/2021 10:30:23] \"\u001b[37mGET /static/2.jpg HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [02/Feb/2021 10:30:23] \"\u001b[37mGET /static/1.jpg HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [02/Feb/2021 10:30:24] \"\u001b[37mGET /static/favicon.ico HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [02/Feb/2021 10:30:40] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [02/Feb/2021 10:30:41] \"\u001b[37mGET /static/bootstrap.min.css HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [02/Feb/2021 10:30:42] \"\u001b[36mGET /static/styles.css HTTP/1.1\u001b[0m\" 304 -\n",
      "127.0.0.1 - - [02/Feb/2021 10:30:43] \"\u001b[37mGET /static/favicon.ico HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [02/Feb/2021 10:30:52] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [02/Feb/2021 10:30:53] \"\u001b[36mGET /static/bootstrap.min.css HTTP/1.1\u001b[0m\" 304 -\n",
      "127.0.0.1 - - [02/Feb/2021 10:30:53] \"\u001b[37mGET /static/logo.png HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [02/Feb/2021 10:30:53] \"\u001b[36mGET /static/styles.css HTTP/1.1\u001b[0m\" 304 -\n",
      "127.0.0.1 - - [02/Feb/2021 10:30:54] \"\u001b[37mGET /static/favicon.ico HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [02/Feb/2021 10:31:00] \"\u001b[37mPOST /about HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [02/Feb/2021 10:31:01] \"\u001b[36mGET /static/styles.css HTTP/1.1\u001b[0m\" 304 -\n",
      "127.0.0.1 - - [02/Feb/2021 10:31:01] \"\u001b[36mGET /static/bootstrap.min.css HTTP/1.1\u001b[0m\" 304 -\n",
      "127.0.0.1 - - [02/Feb/2021 10:31:13] \"\u001b[37mPOST /about HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [02/Feb/2021 10:31:15] \"\u001b[36mGET /static/bootstrap.min.css HTTP/1.1\u001b[0m\" 304 -\n",
      "127.0.0.1 - - [02/Feb/2021 10:31:15] \"\u001b[36mGET /static/styles.css HTTP/1.1\u001b[0m\" 304 -\n",
      "127.0.0.1 - - [02/Feb/2021 10:31:16] \"\u001b[37mGET /static/favicon.ico HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [02/Feb/2021 10:31:33] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [02/Feb/2021 10:31:34] \"\u001b[36mGET /static/styles.css HTTP/1.1\u001b[0m\" 304 -\n",
      "127.0.0.1 - - [02/Feb/2021 10:31:35] \"\u001b[36mGET /static/bootstrap.min.css HTTP/1.1\u001b[0m\" 304 -\n",
      "127.0.0.1 - - [02/Feb/2021 10:31:35] \"\u001b[36mGET /static/logo.png HTTP/1.1\u001b[0m\" 304 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "IMAGE SAVED\n",
      "Before Pred\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Predict Features\n",
      "==================================================\n",
      "GETING Captions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "127.0.0.1 - - [02/Feb/2021 10:33:08] \"\u001b[37mPOST /after HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [02/Feb/2021 10:33:09] \"\u001b[36mGET /static/styles.css HTTP/1.1\u001b[0m\" 304 -\n",
      "127.0.0.1 - - [02/Feb/2021 10:33:09] \"\u001b[36mGET /static/bootstrap.min.css HTTP/1.1\u001b[0m\" 304 -\n",
      "127.0.0.1 - - [02/Feb/2021 10:33:10] \"\u001b[37mGET /static/file.jpg HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, render_template, request\n",
    "import cv2\n",
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "from keras.applications import ResNet50\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Dense, Flatten,Input, Convolution2D, Dropout, LSTM, TimeDistributed, Embedding, Bidirectional, Activation, RepeatVector,Concatenate\n",
    "from keras.models import Sequential, Model\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing import image, sequence\n",
    "import cv2\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "vocab = np.load('vocab.npy', allow_pickle=True)\n",
    "\n",
    "vocab = vocab.item()\n",
    "\n",
    "inv_vocab = {v:k for k,v in vocab.items()}\n",
    "\n",
    "\n",
    "print(\"=\"*100)\n",
    "print(\"vocabulary loaded\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "embedding_size = 128\n",
    "max_len = 40\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "image_model = Sequential()\n",
    "\n",
    "image_model.add(Dense(embedding_size, input_shape=(2048,), activation='relu'))\n",
    "image_model.add(RepeatVector(max_len))\n",
    "\n",
    "language_model = Sequential()\n",
    "\n",
    "language_model.add(Embedding(input_dim=vocab_size, output_dim=embedding_size, input_length=max_len))\n",
    "language_model.add(LSTM(256, return_sequences=True))\n",
    "language_model.add(TimeDistributed(Dense(embedding_size)))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "conca = Concatenate()([image_model.output, language_model.output])\n",
    "x = LSTM(128, return_sequences=True)(conca)\n",
    "x = LSTM(512, return_sequences=False)(x)\n",
    "x = Dense(vocab_size)(x)\n",
    "out = Activation('softmax')(x)\n",
    "model = Model(inputs=[image_model.input, language_model.input], outputs = out)\n",
    "\n",
    "# model.load_weights(\"../input/model_weights.h5\")\n",
    "model.compile(loss='categorical_crossentropy', optimizer='RMSprop', metrics=['accuracy'])\n",
    "\n",
    "model.load_weights('mine_model_weights.h5')\n",
    "\n",
    "print(\"=\"*100)\n",
    "print(\"MODEL LOADED\")\n",
    "modele = ResNet50(include_top=False,weights='imagenet',input_shape=(224,224,3),pooling='avg')\n",
    "#modele = load_model('model.h5')\n",
    "\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "app.config['SEND_FILE_MAX_AGE_DEFAULT'] = 1\n",
    "\n",
    "@app.route('/')\n",
    "\n",
    "def index():\n",
    "    text_to_speech(\"WELCOME TO MY PROJECT \",'Male')  \n",
    "    return render_template('index.html')\n",
    "@app.route('/back', methods=['GET', 'POST'])\n",
    "def back():\n",
    "    return render_template('index.html')\n",
    "@app.route('/about', methods=['GET', 'POST'])\n",
    "def about():\n",
    "    return render_template('about.html')\n",
    "@app.route('/after', methods=['GET', 'POST'])\n",
    "def after():\n",
    "    global model, modele, vocab, inv_vocab\n",
    "    img = request.files['file1']\n",
    "    #a= takeCommand()\n",
    "        \n",
    "    img.save('static/file.jpg')\n",
    "\n",
    "    print(\"=\"*100)\n",
    "    print(\"IMAGE SAVED\")\n",
    "    image = cv2.imread('static/file.jpg')\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image = cv2.resize(image, (224,224))\n",
    "    image = np.reshape(image, (1,224,224,3))\n",
    "    print(\"Before Pred\")\n",
    "    pred = modele.predict(image).reshape(1,2048)\n",
    "    print(\"=\"*100)\n",
    "    print(\"Predict Features\")\n",
    "\n",
    "\n",
    "    text_inp = ['startofseq']\n",
    "\n",
    "    final = ''\n",
    "    print(\"=\"*50)\n",
    "    print(\"GETING Captions\")\n",
    "    count = 0\n",
    "    #final = ''\n",
    "    while tqdm(count < 20):\n",
    "        count += 1\n",
    "\n",
    "        encoded = []\n",
    "        for i in text_inp:\n",
    "            encoded.append(vocab[i])\n",
    "\n",
    "        #encoded = [encoded]\n",
    "        padded = pad_sequences([encoded], maxlen=max_len, padding='post', truncating='post').reshape(1,max_len)\n",
    "\n",
    "\n",
    "        prediction = np.argmax(model.predict([pred, padded]))\n",
    "\n",
    "        sampled_word = inv_vocab[prediction]\n",
    "\n",
    "        final = final + ' ' + sampled_word\n",
    "\n",
    "        if sampled_word == 'endofseq':\n",
    "            break\n",
    "\n",
    "        text_inp.append(sampled_word)\n",
    "        if request.method == 'POST':\n",
    "            text_to_speech(final,'Female')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    return render_template('after.html', data=final)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "            #app.\n",
    "            app.run(debug = False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python app.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from tkinter import *\n",
    "\n",
    "\t\t\n",
    "root = Tk() \n",
    "root.title(\"CRYPTOGRAPHY\") \n",
    "root.geometry(\"800x600\")\n",
    "\n",
    "ent = Button(root, text = \"START\", bg =\"red\", fg =\"white\", command = func) \n",
    "ent.grid(row = 13, column = 2) \n",
    "root.mainloop() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def automate():\n",
    "    from selenium import webdriver\n",
    "    from selenium.webdriver.common.keys import Keys\n",
    "    chrome_options = webdriver.ChromeOptions()\n",
    "    \"\"\"chrome_options.add_argument(\"— headless\")\n",
    "    chrome_options.add_argument( \"—no-sandbox\")\n",
    "    chrome_options.add_argument(\" —disable-dev-shm-usage\")\"\"\"\n",
    "    driver =webdriver.Chrome(\"chromedriver\",chrome_options=chrome_options)\n",
    "    driver.get(\"http://127.0.0.1:5000/\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
